\input{preamble.tex}

\title{Computation}
\author{ian.mcloughlin@gmit.ie}
\date{\today}

\newcommand{\CC}[1]{\textbf{#1}}

\begin{document}

\maketitle

\begin{abstract}
  The following notes are about computation.
  We consider the limits and efficiency of computation.
  We are largely only interested in syntax.
\end{abstract}

\section{Languages}
Start with any set, call it an alphabet and denote it by \( A \).
  For example, take the set A = \{ 0, 1 \} is an alphabet.
  We define strings of length \( i \) over \( A \) recursively:
  \[
    A^0 = \{ \epsilon \}; \ 
    A^1 = A; \ 
    A^{i} = \{ as \mid a \in A, s \in A^{i-1} \}
  \]
  The \( \epsilon \) stands for the empty string\footnote{It's notoriously difficult to depict.}.

  The Kleene star \( A^* \) of the alphabet \( A \) is then union of all \( A^i \) for \( i \in \mathbb{N}_0 \).
  Here \( \mathbb{N}_0 \) is the set of natural numbers including zero: \( \mathbb{N}_0 = \{ 0, 1, 2, 3, \ldots \} \).
  \[ A^* = \bigcup_{i \in \mathbb{N}_0} A^i\]

  A language \( L \) over an alphabet \( A \) is a subset of \( A^* \): \( L \subseteq A^* \).
  Note that the strings in a language all have finite length.

\section{Turing machines}
  Turing machines encapsulate the concept of a computer.
  They are simple machines, consisting of a single read/write head and an infinite tape of cells, all but a finite number of which are blank.  
  The head is over a single cell of the tape and is in any one of a finite number of states at a given point in time.
  Turing machines perform one small step at a time, which involves reading the symbol in the current cell, overwriting it with a symbol, moving to the cell to the left or right, and changing state.

  We define a (deterministic\footnote{All Turing machines will be assumed to be deterministic until we get to section \ref{sect:nondet}.}) Turing machine \( M \) by a 7-tuple:
  \[ M = ( Q, \Sigma, \Gamma, \delta, q_0, q_a, q_f ) \]
  where:
  \( Q \) is a set of states;
  \( \Sigma \) is the input alphabet, not containing the blank symbol \( \sqcup \);
  \( \Gamma \) is the tape alphabet, a superset of \( \Sigma \) containing \( \sqcup \);
  \( \delta \) is a map:
  \[ \delta: (Q \setminus \{ q_a, q_f \}) \times \Gamma \rightarrow \Gamma \times \{ L, R \} \times Q; \]
  \( q_0 \) is the initial states;
  \( q_a \) is the accept state, which is a terminal state;
  \( q_f \) is the reject state, also a terminal state.  
  
  Before the Turing machines begins its operation, a finite number of consecutive non-blank cells contain symbols and the head is over the left-most of these.
  These non-empty cells form the Turing machine's input and can be viewed as a string.

  When the Turing machine operates on an input, there are three possibilities.
  The first two are similar: the machine can accept the input by ending in the accept state or the machine can reject the input by ending in the reject state.
  In these cases the machine stops upon entering these states, which is usually called halting.
  The third possibility is that the machine might never stop operating.
  
  The subset of \( \Sigma^* \) (the Kleene star of the input alphabet) containing all elements that are accepted by the Turing machine \( M \) is called the language of the Turing machine \( L(M) \):
  \[ L(M) \subseteq \Sigma^* \]
  A Turing machine that halts on all inputs is called a decider and is said to decide its language.
  Note it's possible for two distinct Turing machines \( M_1 \) and \( M_2 \) to accept or decide the same language: \( L( M_1 ) = L( M_2 ) \).

\section{State tables}
  A Turing machine can be summarised in five-columned table called a state table.
  Each row of the table describes how to perform the transition function \( \delta \) for a given state and tape symbol.
  Table \ref{table:statetable} gives an example of a state table for a Turing machine that accepts all strings over the alphabet \( \{0, 1\} \) that contain an even number of \(1\)'s, including zero as an even number. 
  \begin{table}[H]
    \centering
    \begin{tabular}{x{1cm}x{1cm}x{1cm}x{1cm}x{1cm}}
      \toprule
      State & Input & Write & Move & Next \\
      \midrule
      \(q_0\) &   0 &   0 & R & \(q_0\) \\
      \(q_0\) &   1 &   1 & R & \(q_1\) \\
      \(q_0\) & \bl & \bl & L & \(q_a\) \\
      \midrule
      \(q_1\) &   0 &   0 & R & \(q_1\) \\
      \(q_1\) &   1 &   1 & R & \(q_0\) \\
      \(q_1\) & \bl & \bl & L & \(q_f\) \\
      \bottomrule
    \end{tabular}
    \caption{Turing machine state table}
    \label{table:statetable}
  \end{table}
  Provided we adopt some conventions, the state table can be used to describe the whole Turing machine.
  First, the initial state is the first one listed in the table.
  Second, the tape alphabet is given by the distinct symbols in the second column.
  Finally, the only difference between the input and tape alphabets is the blank symbol.
  Note that there is single row for each combination of state and tape symbol.


\section{Decision problems}
  A decider makes a binary choice for a given input: accept or reject.
  The Turing machine \( M \) in this case performs a map:
  \[ f:\Sigma^* \rightarrow \{ q_a, q_f \} \]
  Sometimes this map is called an indicator function, as it indicates which elements of \( \Sigma^* \) are in \( M \).
  In general, a map from a set to any set with two elements is called a decision problem.
  So, a decider performs a decision problem.

\section{Complexity}
  A decider takes a finite number of steps before halting on a given input.
  We are typically interested in knowing the maximum number of steps \( f(n) \) the decider takes on all inputs of length \( n \).
  We use the number of steps as a proxy for time --- it's common to call the number of steps the \emph{time} the Turing machine takes.
  We can often express \( f(n) \) using a simple formula.
  For example, the Turing machine in Table \ref{table:statetable} takes \( f(n) = n + 1 \) steps on every input --- reading every symbol of the input and the blank after it before halting.
  
  We are interested in knowing how \( f(n) \) grows in relation to \( n \).
  For this, we use big-O notation:
  \begin{definition}
    A function \( f(n) \) is said to be \( O(g(n)) \) if there exist two positive integers \( c \) and \( n_0 \) such that \( cg(n) \geq f(n) \) for all \(n \geq n_0 \).
  \end{definition}
  In the previous example, \( f(n) = 2n + 2 \) is \( O(n) \) which can be seen by setting \( g(n) = n \), \( c = 3 \) and \( n_0 = 2 \) as per Fig. \ref{plot:2n2}.
  \begin{figure}[H]
  \begin{tikzpicture}
    \begin{axis}[xmin=0, xmax=6, ymin=0, ymax=20, axis lines = left]
    \addplot[smooth, domain=0:6] {2*\x + 2} node[below right, pos=0.8] (endofplotsquare) {\(2n+2\)} ;
    \addplot[smooth, domain=0:6] {3*\x}     node[above left,  pos=0.9] (endofplotsquare) {\(3n\)} ;
    \end{axis}
  \end{tikzpicture}
  \caption{\( 2n + 2 \) is \( O(n) \)}
  \label{plot:2n2}
  \end{figure}
  We usually define the complexity class \CC{NTIME}\((f(n)) \) as the set of all languages for which there is a decider that takes \( O(f(n) \) steps.

\section{\CC{P}}
  We denote by \CC{P} the set of languages that are each decidable by some Turing machine in \( O(n^k) \) steps for some \( n \in \mathbb{N} \) where \( \mathbb{N} \) is the set of natural numbers without zero, \( \{ 1, 2, 3, \ldots\} \).
  Using the \CC{NTIME}\((f(n)) \) definition above, \CC{P} is equivalently defined as the union of \CC{NTIME}\((n^k)\) for all \( k \in \mathbb{N} \).
  
  The \CC{P} is short for polynomial.
  Here, we define a polynomial is an expression in a variable \( n \) made up of constants (elements on \( \mathbb{N}\)), powers of \( n \) to a constant, addition, subtraction and multiplication.
  For example, \( n^5 + 2n + 4 \) is a polynomial whereas \( 2^n + n^2 + 5 \) is not because it is made up of something other than those elements listed above, namely \( 2^n \).



\section{Non-determinism}
  \label{sect:nondet}
  We consider now a modification to Turing machines: we allow the Turing machine to transition to zero or more states simultaneously from a given state when reading a given symbol.
  This requires a modification to the transition function as follows:
   \[ \delta: Q \times \Gamma \rightarrow \Gamma \times \{ L, R \} \times \mathcal{P}(Q) \]
   where \( \mathcal{P}(Q) \) is the powerset of \( Q \) --- the set of all subsets of \( Q \).
  From the state table point of view, the effect is that there may be zero, one, or more rows for each combination of state and tape symbol.
  In practice, we can view this as the Turing machine being able to fork, at will, into two or more branches of computation.
  Note that every deterministic Turing machine is basically a non-deterministic Turing machine\footnote{You do have to change the transition function to map to \( \{ q \} \) rather than \( q \), but that's a trivial change.}.

  We say an input is accepted by a non-deterministic Turing machine if any of its branches end in the accept state.
  It may be that other branches end in the fail state or compute forever.
  If all branches halt for all inputs, we say the non-deterministic Turing machine decides its language.

  How does non-determinism affect the computations Turing machines can perform?
  The bad news is that this doesn't give a Turing machine any extra power.
  Turing proved in his 1936 paper \emph{On computable numbers with an application to the encheidungsproblem} that some languages are not the decidable by any Turing machine.
  There are even languages that cannot be accepted, let alone be decided.
  Allowing non-determinism does not change the languages that can be allowed or decided.

  However, it is not known whether computations can be done more efficiently on non-deterministic Turing machines.
  Examples abound of efficient non-deterministic Turing machines that accept or decide languages for which no known efficient deterministic Turing machine is known.
  It is unknown whether such deterministic Turing machines exist.
  A special case of this question is the \CC{P} versus \CC{NP} problem.


\section{\CC{NP}}
  The \CC{NP} complexity class is the non-deterministic equivalent of the deterministic \CC{P} complexity class.
  Define \( NTIME(f(n)) \) as the set of languages decidable by a non-deterministic Turing machine in \( O(f(n)) \).
  Then, \CC{NP} is the set of all languages decidable by non-deterministic Turing machine in \( O(f(n)) \) steps.

  Given that non-deterministic Turing machines may fork into many paths, how should we count the steps they take?
  The common way to count this is to consider the longest path taken, irrespective of whether it accepts or rejects.
  Thus a non-deterministic Turing machine takes \(O(f(n))\) steps if the maximum number of steps in its longest path on an input of length \(n\) is \(O(f(n))\).

  Note, because every deterministic Turing machine is also a non-deterministic Turing machine, every language in \CC{P} is in \CC{NP}.
  So, \CC{P} \( \subseteq \) \CC{NP}.
  The \CC{P} versus \CC{NP} problem is to determine whether \CC{P} \( = \) \CC{NP} or \CC{P} \( \subset \) \CC{NP}.

\section{Church-Turing thesis}
  The ideas surrounding Turing machines arose from Turing's investigations into computability.
  Alonzo Church was Turing's PhD supervisor and developed an equivalent system called lambda calculus.
  By equivalent, we mean that any computation that can be done on a Turing machine can be done using lambda calculus and vice versa.
  Lambda calculus is the basis for functional programming languages, and the difference between functional and imperative programming languages is mirrored in that between lambda calculus and Turing machines.
  
  Turing and Church were working on ideas posed by G{\"o}del and Hilbert which concerned the foundations of mathematics.
  Hilbert asked if mathematics was algorithmic in the sense that true mathematical statements could be deduced by some procedure from axioms.
  G{\"o}del had shown that there must be some statements in mathematics that are true but cannot be proved.
  Church and Turing proved, while developing their computational systems, that their systems could not compute everything.
  What has become known as the Church-Turing thesis is the idea that what we as humans think of as computation is perfectly encapsulated by Turing machines and so the limits on computation are real --- they are not just features of Turing machines.

\section{Reductions}
  Ultimately the output of a Turing machine is a binary accept/reject decision.
  However, Turing machines also have another type of output: what is left on the tape once the machine halts.
  We might care about this, for instance, if we are interested in running two Turing machines sequentially on the one input.
  The first Turing machine might manipulate the input in order that the second Turing machine receives that input altered in some way.

  As an example, consider the language \texttt{EVENPARITY} containing all strings over the alphabet \( A = \{ 0,1 \} \) that contain an even number of \(1\)'s, including zero as an even number.
  Thus, \texttt{EVENPARITY} \(= \{\epsilon, 0, 00, 11, 110, 101, 011, \ldots\} \).
  A simple Turing machine decides this language, as per Table \ref{table:statetable}.
  
  We can use this Turing machine to decide the language \texttt{ODDPARITY}, containing all strings over \( A \) that contain an odd number of \(1\)'s, provided we use the machine given in Table \ref{table:oddparity} on the input first.
  \begin{table}[H]
    \centering
    \begin{tabular}{x{1cm}x{1cm}x{1cm}x{1cm}x{1cm}}
      \toprule
      State & Input & Write & Move & Next \\
      \midrule
      \(q_0\) &   0 & 0 & R & \(q_0\) \\
      \(q_0\) &   1 & 1 & R & \(q_0\) \\
      \(q_0\) & \bl & 1 & L & \(q_1\) \\
      \midrule
      \(q_1\) &   0 &   0 & L & \(q_1\) \\
      \(q_1\) &   1 &   1 & L & \(q_1\) \\
      \(q_1\) & \bl & \bl & R & \(q_a\) \\
      \bottomrule
    \end{tabular}
    \caption{Append a \(1\)}
    \label{table:oddparity}
  \end{table}
  In state \(q_0\), this machine scans from left to right across the input and puts a \(1\) in the blank cell at the end.
  Then it moves to state \(q_1\) where it moves back from right to left, until it overshoots the original starting point by one cell and then moves right one cell to that exact point.
  Note the machine always accepts, no matter the input.
  The net effect is that the head is back in the same starting point on the tape and a \(1\) has been appended to the original input on the tape.
  Giving this new input to the Turing machine in Table \ref{table:statetable} will lead to an accept if the original input contained an odd number of ones and reject otherwise.
  We call this a reduction from \texttt{ODDPARITY} to \texttt{EVENPARITY}, denoted as \texttt{ODDPARITY} \( \leq \) \texttt{EVENPARITY}

  How many steps \( f(n) \) does the Turing machine in Table \ref{table:oddparity} take on an input of length \( n \)?
  It scans across the input, then reads the blank at the end and moves left, back to the last symbol of the original input.
  That takes \( n + 1 \) steps.
  It then scans to the start of the input and reads the blank just beyond that before accepting, taking another \( n + 1 \) steps.
  It total, that's \( f(n) = 2n+2 \) steps --- a polynomial.

  What we have shown is that the \texttt{ODDPARITY} decision problem can be converted into \texttt{EVENPARITY} decision in polynomial time.
  By converted into, we mean that anything in \texttt{ODDPARITY} is converted into something in \texttt{EVENPARITY} and anything not in \texttt{ODDPARITY} is converted into something not in \texttt{EVENPARITY} so that the decider for \texttt{EVENPARITY} can decide \texttt{ODDPARITY}.
  The fact that the conversion happens in polynomial time is significant, as the sum of two polynomials is a polynomial.
  Thus if \texttt{EVENPARITY} is in \CC{P} then so is \texttt{ODDPARITY}.
  This essentially means that \texttt{ODDPARITY} is no more difficult to decide than \texttt{EVENPARITY}.

  Note a quirk in this situation: \texttt{EVENPARITY} can be reduced to \texttt{ODDPARITY} using the same set up.
  The two problems are considered equivalent.
  This is not always the case --- sometimes we can only reduce in one direction.

\section{\CC{COMPLETE}}
  In 1971, Stephen Cook proved~\cite{cook71} an interesting result: there is a language to which all of the languages in \cc{NP} can be reduced in polynomial time.
  Since then, a number of languages have been shown to have this property.
  They are called \cc{NP-HARD} because they are at least as hard as each of the languages in \cc{NP}.
  The language that Cook used is itself in \cc{NP}.
  Languages that are both \cc{NP-HARD} and in \cc{NP} themselves are called \cc{NP-COMPLETE}.
  


\section{Undecidable problems}


\bibliographystyle{ieeetran}
\bibliography{bibliography.bib}

\end{document}